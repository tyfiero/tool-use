{
    "title": "Synthetic Data Generation and Automated Research Assistant - Ep 1 - Tool Use",
    "channel_name": "Tool Use",
    "publish_date": "2024-08-20T13:01:07Z",
    "processed_date": "2024-08-24T16:11:15.810451Z",
    "view_count": "124",
    "like_count": "16",
    "comment_count": "10",
    "duration": "PT36M43S",
    "video_id": "uAo513GIwoU",
    "description": "Join Mike Bird and Ty Fiero as they continue their exploration of AI tooling, sharing practical examples that you can use today. In this episode, they explore web scraping, its applications, and its connection to AI\n \n #Tools\nGenerate a synthetic data set from a prompt and train a model on it\n\nUse an automatic research assistant to generate learning material on any subject\n\n#News\nAnthropic launches Context Caching\n\nNous Research launches Hermes 3\n\n#Code \nwww.github.com/MikeBirdTech/ai-toolkit\nwww.github.com/tyfiero\n\nNext week, AI and video\n\nConnect with us to keep the conversation going:\nwww.x.com/ToolUseAI\nwww.x.com/FieroTy\nwww.x.com/MikeBirdTech\n\nSubscribe to Tool Use for more episodes on AI tooling and how you can use it to improve your life!",
    "channel_id": "UChZeiM9f9fViEYK2VPRx_dw",
    "thumbnail": "https://i.ytimg.com/vi/uAo513GIwoU/hqdefault.jpg",
    "transcript": "welcome to episode one of tul use with me as always is Ty Fiero and I'm Mike Bird we have a weekly conversation around the latest AI tooling and how you can use it in your life by producing practical examples and projects with it we also cover some of the AI news that didn't make the headlines but we feel you should know about it this week we're going to be discussing web scraping Ty tell us about web scraping okay so web scraping is basically plundering the internet to train giant language models to replace us no no just kidding just kidding but web scraping is actually taking useful information from websites to do cool things with it and so how it's used in AI right now is uh a little bit uh perhaps controversial but you know image Ai and startups like mid Journey whatever else scrape the internet of all the images so that they can use those to train their own models um there's even Nvidia in hot water right now for scraping YouTube and scraping all sorts of different video platforms for their own video creation model um and then of course chat gbt gpt3 is trained on the pile and the pile was this data set that was a gigantic web scraped set of pretty much everything on the internet um what's most exciting to you about web scraping I view it as kind of like the consolidation of knowledge if I'm going to spend some time like going through Duck Duck Go finding different results and just like making notes as I research a topic um it's very time intensive web scraping you can kind of offload a lot of that to let the robots take take care of it for you um and then yeah it's kind of what you do with it where I think is the the ethical dilemma um one note on the pile I heard it used to be no one really cared about what was in it until people started making billions of dollars with it then all of a sudden you had companies going through the fine tooth conb being like Oh there's a bit of copyright material in here can't use it so a lot of the open source AI initiatives are actually struggling for the data they can use because when you're a big company you have team of lawyers you can really like stand up for yourself in these situations but the small nonprofit Labs as soon as they're starting with the lawsuit they have to just pull the plug so a lot of labs and even like University Research labs are struggling to release the content they want to even though they're team open source and they want to put it out there because a threat of legal liability so not for this episode but in the future I think we should definitely look into how we can as a community come together and start creating robust data sets that are like truly user generated completely copyright free because because of web scraping creating these large data sets which have been widely used we just don't know what's in there and it's tough so I like using web scraping to expedite the process of research and I think that'll tie into my demo today but in general use it for ethical things and I don't think you have a concern totally makes sense that would make a great episode at some point doing like data collection i' love to like write a script or something to record everything I'm doing on my computer and train a model to be like like me or something there's some cool ideas that we could do there yeah added to the list okay deal it's on the list all right well I guess I can show off My Demo First here you went first last week so I'll I'll jump right in here and kind of show you what I got all right for my demo this week I played with EXA AI which is a really interesting llm platform for scraping data on websites and kind of just generally getting information off the internet so I made this little demo I'm actually just going to run it and kind of explain it as it runs okay so first step I did is actually use dsy to optimize the user query so the user query right now is like give me the hottest startups from 2024 and then it's going to actually make a better user query that takes that information and expands upon it and then I have a summarizer prompt that's from DSP that's going to take this optimized user prompt and then it's going to take that optimize it further so that we have a really good summarization prompt that we can use later so now this is actually a um prompt we can use there and then I pass this into EXA so I'm actually passing in the user query and I'm passing in a summarizer prompt into EXA because EXA has a built-in summarizer which I think is fantastic so it'll go look at a particular website take the information from it and then you can do things like highlights that'll take like a highlight off the website um like the top thing can also just get you the text of the website it can get you the title of the website um or it can get you a full summary of the whole page um and you can pass a custom prompt into the summarizer of this and it gets you some pretty interesting things so here I have some EXO responses here's response one this article highlights most promising startups talks about Adept and Alpha sense and some of these other ones and then I did this other thing so once I get this extra response I'm actually going to use anthropic to generate a uh a likely user query that would have resulted in this and so without actually having a user query there it's going to take this and work backwards and be like okay they probably asked this to get to this answer and then I run this again and then here's a Twitter posts what's the current state of venture capital so it's actually making a user and assistant on each one of them here it keeps going yeah so this just keeps going so I I have in my code just like an end value to see how many responses you actually want to get back I set mine to five currently but yeah it's making a response it's making a user query and then at the end of all of this we generate a likely system prompt so we actually put into the context window of anthropic three results one and it's formatted in like open aai format to where you have like Ro user you know content these and then we have Ro assistant content this I pass that into a prompt for anthropic that's like given this conversation between a human and assistant what is the likely system prompt that would have resulted out of all of this and it actually generates a system prompt and so you're an AI expert specializing in startup Adventure Capital trends provide informative responses and then I set this up to actually take all of this information and create Json L files so we actually can create a Json L and it makes a whole training data set so now we have Json L training data took about 25 seconds to do Five results Five results is nowhere near what you really need to make a really good model but we can actually see here that we have a trading data jonl and this has the format You' need to fine tunee a model and then what I can actually do is I can go into open pipe I can make a new finetune let's see here I don't really like the name of that let's just call it EXA here let's do yeah sure llama 3.1 actually I kind of want mistl that sounds more fun to me and then I can oh I need to add a new data set okay wait hold on I got to go back and add a data set data set new data set and then I can upload data which just might most recent one this is only five examples this is a terrible fine tune do not try this at home you should go make at least probably a 100 to 1,000 examples just to even get anything close to a good model but we're going to make one on five examples anyway just because it's fun here okay August 17th I'll just call this EXA base model I want mistol insufficient oh I need at least 10 okay well I'll show you I have this data set from yesterday that I had which is 50 samples um and I'll just start training that and then I'll just start training I think this took about maybe like 10 minutes to train um and it also cost me about like 30 cents to make my own model that has this information on it probably be a little more expensive if you had a th but I bet it's actually not that much more it's probably like six bucks to train your own model um and then I can actually I will show you what I have over Oh wrong one and go here here let's clear this out and I actually have I can call my fine tune that I actually have so this is just calling the fine tune that's hosted in open pipe so I asked it something like what are the top startups and then this there's some playing around in here that needs to happen it's not like I don't want this response to say this website ideally this would just like come back with a essentially hallucinated AI startup so you can come up with cool startup ideas that was the idea here couldn't quite get the messaging on it quite right but um yeah we have a our own custom model living on open pipe because they make it super easy and now we have a model we can call however we want to and that's kind of the whole thing here but I can walk through some of my code just a little bit to show you kind of how things are working um let's see here we got X AI so I kind of I like having all of my changeable variables at the top so here's our provider this worked with Olam as well so it can be fully local not quite as impressive um you can also play with open AI I actually found that open AI has slightly better results than anthropic which made me kind of sad because I love anthropic but is what it is I still chose anthropic because it's a hill all die on um and then you can specify your search query here this was this could be anything I had this yesterday of like what are some fun facts and it would go through and find a bunch of websites for fun facts pull the fun facts out of them and then use those as responses you can even make a fine-tuned mistal model that all it does is just hallucinate fun facts for you which I sounds fun to me at least I don't know how useful that is but you can imagine actually doing useful things with this too I mean you can have this scrape different websites and maybe it's like I don't know company profiles or there's all sorts of things you could do with this I mean the internet's full of interesting information why not scrape that information throw it into a model and have it yourself um so but yeah you can specify models here this is where you specify the results I mean and ideally you'd set this to like 10,000 but uh I am not made of money so I did five for today um I'm not here to train the next huge model and then we just set up a EXA and props to EXA they made this easy they have a API playground online where you just like can specify a couple things and they don't just give you the curl request or like the API call they're like here's the python code just copy and paste and it just worked just out of the box no no  around with it which is incredible um but yeah so I have a llm response and I just kind of set this up to have a cheap model and a state-of-the-art model for the cheap model after every result that comes out I want to use a cheap model instead of a state-of-the-art because that would get really expensive but I have the State ofth art make the system prompt and some of these other different things just for uh quality sake yeah we just have some dpy signatures here create the user query I love dsy it's super easy to do this look how simple this is you just specify your a prompt you specify a user field in your optimized prompt and you have like a forward function and it just returns The Prompt super straightforward did the same thing for um the search prompt so it kind of just does all that here's just the optimizer and this is actually interesting too for dspi is you can actually provide examples to this so I have this Optimizer here right so I have the meta prompts and the different inputs that go into it and then we just provide a list of examples of like okay this is what this is a good example I actually handw wrote this one um and then this is a prompt that should lead to this output and then we have Supply the input here and then here's another one this is about apple piie recipes which is a weird theme that keeps recurring on this podcast for some reason uh but so you actually have these examples here and then you can do this thing called bootstrap few shot and so it's thing called telepromter thing I don't like about the pi is or naming of things I wish they made it a little bit more interesting that should just be like an Optimizer but anyway kind of goes through this and it creates these prompts based on the examples and based off of your class you set up here anyway I love DSP I'll talk about this all day long but it makes some cool stuff there um and then this is literally all my exit code like props to them like look how easy that is that's what 11 lines of code search contents pass and search query type neural which uses rag um so I'm sure they probably already have some results like cached or saved in a vector database um they actually have their own Auto prompt too so if you pass in a query they're going to format The Prompt in a way that makes sense for their system um then you specify them results you pass in the query y this is an interesting one this generate training data function is actually kind of useful I think I'll use this in other projects now take any amount of of data that has an AI assistant result and a user query and you can generate a Json L file kind of just goes through here adds the system prompt whatever else and then boom you get a system prompt or a um Json L file you can train a model with and then it just kind of spits it out but yes so this is kind of everything that's going on here optimize user query optimize a summary prompt get your responses from EXA generate your trading data and tell me how long it took and then I just go right into open pipe I tried actually to open pipe does have an API and they do have an API for fine-tuning but it's definitely in Alpha and I couldn't figure out how to upload a data set to it I think you have to upload a data set to the web app and then specify that as a fine tune which seems kind of weird to me I wish they were able to upload a training set find- tun a model and then just all in the same thing be able to call it from there would have made for a much better demo just from a single like forword user query to a custom model that you can talk to Wild I mean these are the times we're living in um but yeah I think that's I think that's everything I got awesome man I really liked it I think like another side effect of this which is sweet is not only do you get to fine tuna model on a more specific topic that you're that you're wanting to focus on but you're actually because you're leveraging EXA you can actually get past the training cuto off date and give it brand new information so if you were to say scrape news articles you could actually find tuna bottle to be like up to date on what going on with certain topics and not you know knowledge cut off eight months ago so I think this has a bunch of Downstream effects to' be really cool and yeah I'm glad you gave a shout out to the open pipe guys because they make really good stuff but you know oh user feedback like this is probably helpful some of their corporate Brothers will reach out and uh I definitely reached out to them and so I I hope to see a better fine-tuning API I mean if you're actually going to make a model that's going to cost you a bunch of money you're probably not going to send that from your command line you probably just want to go to the web app and actually just upload it but I wish it was is there one interesting thing is actually EXA has on their website they say that there's a whole service they provide for creating training data for language models and what actually prompted this whole demo is the fact that you can't just get started with that you have to talk to sales and I was like nah I'm not talking to sales I'm going to build them myself and so I just took their their service and kind of built reverse engineered their um actual trainer set training set generation pipeline I'm sure theirs is probably more impressive than my 300 line python file here but hey I'm using exess scraping the internet for results and creating a custom MST model pretty wild love it good job man that was awesome thank you all right I think I'll pass the torch over to you I put together a research assistant like I mentioned earlier I I like the idea of being able to aggregate information in uh an easy way just to save me time so the goal was save 90% of the time that you're going to spend researching a topic not produce the output of like an essay or anything but just get most of the way there so uh python research assistant and now like before I can set the server so I'll use Gro to keep it speedy and then you enter in the research topic so let's say migration pattern of puffins and I have this setup where will actually export to this obsidian Vault so you can see I have a research directory so with within the research let's create a directory called puffet and then you send it on its way so it also uses EXA but the purpose of exit is to mostly just grab the results with small summaries and then I feed it through fir crawl now fire crawl is a service I use I've been hosting it locally but you can pay for their API where it'll take a URL and intelligently scrape everything from the website um I did use beautiful soup to kind of clean it up a bit but you can see here we get the EXA results where it just gives you the link to it the title a little summary but then we feed it into fir crawl where it gets the massive amount of data now this itself is pretty useless so what I'm doing is it'll generate individual summaries of each one so it makes six AI calls for six results and that is a configurable number and then it creates a summary so you can enjoy the learning so open up your summary and it'll have the migration pattern of puppet a comprehensive guide and we have an executive summary so just a couple sentences explaining what it is some key Concepts you can understand the general gist so if you're coming to a subject completely green complete novice you'll be able to understand a few definitions then we get a detailed outline and then this is somewhat hardcoded but I did give the LM the ability to fluctuate a little bit in what includes there so we have some extra pain consensus PS are complex and influenced by various factors including climate change sea ice and food availability uh cool I tried to get to Source it did it unreliably but I do include all of the the EXA uh results at the end so it gives you instructions for which you want to learn more uh suggested learning path so this is really just going to be the foundation to get started um and I was like you know puffins are great but let's uh let's say we want to do something a little more technical so research assistant once again we'll use Gro keep it quick and then this can be uh long context llms versus rag uh output can be llms but I also add added a technical flag so anytime you have a technical subject that you want to research you pass in this flag starts off the same search as EXA but instead of getting six results from EXA it does three and then it searches archive so archive is a collection of Open Source papers where they have an API that can get you like the link the title a summary but it also included the ability to download the PDF uh OCR uh optical character recognition of the PDF and takes all the contents there so within l M we have both the exra results like before but also the archive results and then same process it'll pass all six results through fir crawl generate the individual summaries then generate the comprehensive learning material because this is also parsing the PDF it takes a little bit longer but if you were to say read these papers yourself this whole process is a single percent less than a percent of the time you'd be spending uh to give you that foundational understanding so we check out the summary study of large context LMS and Ray has gained sufficient attention the field of NLP and then it'll go through some key Concepts again um some comparison studies advantages and limitations to both and then General expert opinion some real examples and once again we include all of the summaries at the end so this way you're able to get not only a AI generated summary of foundational knowledge for a given topic but you're able to get sources so you can dive in and learn more because coher does a wonderful job with grounding but if you want to use different services or build your own system it is important to make sure that you actually link to proper material so with this using Gro um you can set up the service to use AMA locally or anthropic because I I agree Claude is uh 3.5 Sonic is the the Top Model right now for my results um you're able to have the versatility to work this into your system now this is it's it's good I would say there's a lot of room for optimization for the promps but I spun this up relatively quickly and then you can work with tools like um DSP to improve the prompts to actually increase the results so you're able to automate researching a topic so you don't have to ask someone to spend so much time going through Google results you can actually just have the AI do it send it back to you feed this into deeper pipeline like I said now this is in obsidian and if you pay attention to last week we have open interpreter able to work in obsidian so maybe open interpreter could take some results from this summary and act upon it um so that's my demo you basically just built perplexity you going to go raise your series a round now or what we'll do it to Ed to the Moon um W that's wild man that's crazy I just absolutely love the fact that you keep making the demos work with ins cityian like it's your you didn't just print everything to the the console and terminal you're like no I'm going to have everything print out in obsidian in my custom Vault like this is this is this is knowledge like you're building a knowledge base here and obsidian has all sorts of cool tools for that you know with linking different files between each other and creating links you can even have another step here that just creates links goes through all the different files you went to and actually links things between the things then you can have that what's that little view in obsidian that shows you all of the yeah the graph view I believe graph view yeah yeah yeah I mean look at that that's wild I mean you just did that yeah and that's the thing if we do better need and also this like firecrow results this was just an artifact to help with testing you don't need this you can just get the results if you want the grounded truth and then your summary or you can just spit up the summary rename it something more appropriate instead of just summary say like this is actually like lm's versus rag or sorry long context versus rag this is puffing stuff and then your graph you will be able to connect different bits of information together and potentially connect it to your uh your internal knowledge base or whatever so I think using a single common knowledge based store is going to be immensely valuable so I do intend to making a lot my tools working with it incredible man that's that's impressive you know in like uh like UFC fights where at the very end they have the two people there then they raise one of the hands for the winner I think you won this week I'll beat you next week but I think you're demo blows M out of the water that is crazy man I think using these together will be sweet because once we start building up a model that we can point our research assistant at that is trained on a certain topic I don't know I I think incorporating EXA into these tools just makes them so powerful um actually I want to touch on Fir crawl quickly because I kind of glossed over it fir crawl is a service where I have it running self-hosted for free on my local machine uh you can pay for their API or you can put it up in a server but what fir craw is cool is not only can you use the scraping functionality like I did where you give it a URL that EXA captures and then it'll scrape all the content you can set off to crawl we actually start a job and then it goes to the URL you give it and then it'll actually also hunt down the subdomains to to uh scrape as well so if you give it uh example.com to the crawl method it'll give you the results for that Page Plus like the slab us SL contact usblog so you can actually get it to really go down deeper and capture more information so if we were to take this research assistant and give it the ability to crawl instead of just scrape it you might be able to find more details deeper down try to make different associations so I think this is a great starting point but people and this will be up on my GitHub for free people can take it play with it make their own businesses around it but the ability for it to go even deeper into knowledge and create uh more abstract connections will be very interesting to see yeah wow that's really cool I we should definitely use this on the podcast in future episodes to research topics I bet you can even just ask it like best podcast themes for an AI themed podcast it would go off and make a bunch of research and come up with some Co ideas for us that's awesome wow fire crawl and EXA that's I'm impressed I was I I went on ex's website initially and I was like all right here's the the sales pitch all right sure but then actually play with it and try it and read the documentation and it's like oh okay I see I see what the where the value is here this actually really crazy yeah and and I hope more open source people enter the space but I mean X's has not expensive for me so I've been very happy with it so far all right Ty what did we uh what did we miss in AI news this week okay so I thought anthropic their release this week was absolutely insane I think it's absolutely crazy and this Alex Albert guy is honestly just one of the best like Community managers I've ever seen but anyway the prompt caching in the anthropic API I think is so much bigger than people really think it is like dropping API cost by 90% and look two lines of code you literally just add cash control and you add a couple extra headers the first time you send it it's like slightly more expensive I think by a couple cents and then it's cash that context and then you can send whatever you want to it so I mean here's the pricing whatever else he even made an interactive cost savings artifact which I think is such a brilliant idea idea too super cool I mean look at this your system instruction is grounding data it actually shows you your savings like look at that $46 versus $320 wild wild I mean this also like saves the planet right we're using less electricity there's less cost here I just think it's way bigger than people give it credit for and I it's also so easy to do I did it in 10 minutes this morning we've got I just have this tiny little python script got our model I actually have a book that I took the txt of and then I add prompt caching into it and then I can just run it I think let's see where was it in here oh well just run uh actually C dot dot Pi let's see here prompt caching I think it is yeah okay prompt cash and oh it's probably taking a while because it's a whole book I kind of forgot about that there it is nice and then we have uh cap response ropic got some actual takeaways from the actual book I think that's crazy um I a lot of you out there that are in AI probably heard about this week but I think it's so big that I want to Rea it up in case anyone hasn't seen it what are some uses for context caching like would it uses for every single call or like when does it have its value I it's a good point I mean I think for startups it could be really big like if you have a gigantic system message sending that along with every request gets expensive so you can just cash your system message and then every response that comes through you just use the same cache I think that's a probably the most straightforward use case of this just to save costs but I plan on using it to upload my whole code base to it I mean there's a really cool GitHub repository actually called code to prompt with the number two to prompt and it's written all in Rust and basically run it at the root level of your repository and it recursively goes through each file and dumps it into a context um and it also is smart enough to like ignore obvious things it should ignore like node modules and py cach um and then it make one gigantic text file and now you can take that one giant text file send it to anthropic with CLA three and a half sign the first request might cost a little bit more but everything after that is way cheaper so you can have full conversations with the code base and make a new chat and all of a sudden you're off to the races on a whole different thing so I think it's really fascinating yeah I can't think of a faster way to get a new Dev on board to a code base like if they can just chat with anthropic and now like prices dropped dramatically because it's all cash there this sounds like a huge accelerant to get people on board into especially like Legacy code when things are complex and things have been abstracted away over the years being able to just have Claud say oh yeah like this is it and then you know generate a mermaid chart for it so yeah saving cost there seems immensely valuable and I bet it's what they've been doing in the anthropic like if you go to claw the actual web application I bet that's what they're doing behind the scenes in projects is they're probably taking a lot of the context not putting all of that into the context window necessarily but they're probably like summarizing it and adding that to the system message um so yeah I bet they're already I bet they've been using this for months and are now just releasing it also Google's doing something too with that with Gemini but then you have to use Gemini so use anthropic all right Mike what about you what do you got I want to touch on a new open source model that dropped Hermes 3 Hermes 3 from news research or was SE Canada new research they do wonderful work in the open source community in fine-tuning so Hermes 3 is a fine tune of llama 3.1 they released 8B 7B and 4 5B and the biggest thing is this model boasts comparable and Superior performance to llama 3.1 while unlocking deeper capabilities in reasoning and creativity so I love this I love what they've been doing they just put it out there one thing I dove through the technical report and just a few things that stood out to me that I wanted to touch on the training data strongly encourages model to follow the system and instruction problems exactly and neutrally so you don't have that uh moral uh grandstanding that a lot of models have this will actually do what you want it they it won't refuse instructions on moral grounds which is awesome and I wanted to read this this paragraph large language models have very limited direct agency rather it is the systems and applications that we as humans build with them that give them any degree of agency to the outside world we believe that a more appropriate place for guardrails and active intervention is at the larger systems level rather than on the model themselves which can result in an a priority lobotomization and potential lines of thinking for Hermes there is no such thing as latent thought crime and this hits like this really resonates with me they are trying to make sure the model stays truthful and it's a tool that the human is using so if you want to compare llama 3.1 to this um sorry before I get to that there were a cool thing I've noticed where they actually used the reserve tokens so tokens uh sorry L 3. tokenizer that weren't used they've added scratch Pad reasoning inter monologue planning so it actually has a lot more agentic capabilities than classic llama 3.1 their training data set was approximately 390 million tokens and here's the distribution I encourage you to check out the tech technical report if you haven't read it and then the results you can see between llama 3.1 and Hermes 3 it does go back and forth Hermes does better on a few like higher than average than llama 3.1 but this just shows that like meta putting out their version and then Hermes 3 fine-tuning it even if it's comparable in performance but Hermes 3 does better than some Hermes 3 gives you the ability for to stay in character longer to be more obedient be a model that you control so I definitely encourage everyone to check it out you can download it from hugging face they have some ggfs as well as the full model if you want to try it before you download it open router. AI for a limited time does have it free as well as llama chat so there are multiple ways you can go online try this model today I encourage you to download it noose does awesome work check out on Discord and uh yeah let's us know what you think about it wow that's incredible that sounds like a fun model to play with I feel like that would be a great model to play with in sort of these like do do you see that uh Infinite Back rooms thing with Claude where like there really cool repo out there or maybe it's just a demo but I think it's a repo called infite back rooms and Infinite Back rooms is like basically getting two versions of Claud on it to talk to each other about like life and about Consciousness and about like The Human Experience and going deeper and deeper and encourages it to get deeper and deeper and deeper into into the most wild like Consciousness conversations to the point where sometimes after a couple turns of this one of the models will start to panic and say okay enough I'm done I don't want to talk about this anymore let's talk about something else it's really wild so feel like this new model I know it kind of goes dark but it's pretty interesting that even they have some sort of uh anyway but I think new new model actually be pretty cool for that because it doesn't have all of these different biases or whatever else it could really just be kind of unhinged yeah I want to get a a llama file made up of it um when I checked earlier today it's not an a llama but it might be out there by now um and just yeah play with it especially seeing things like the uncertainty around character Ai and where they're going having an open source model that will adhere to a certain Persona that should work well in like crew AI type situations where you actually have like a product manager a project manager a researcher and you can have them really stay in character for an extended period of time I think this is actually going to be a pretty big unlock and the fact that they just opened it up open weights it's new so they have their data set out there it's uh a very cool product that I think will unlock a few more use cases great call out I actually did miss that one this week which is actually crazy it worked it worked the system that did work this is why we do this every week to try to teach each other something exactly just bring people along for the ride yeah exactly wow this felt like pretty good episode this this week I'm I'm excited to to watch this one back actually actually what do you think about for next week what we what should we build what we what should we play with so I've really been enjoying how we're building things that kind of like help us out so what do you think about like video editing or something along the lines of of using video in AI okay building the machine that builds the machine I'm here for it let's let's build things that help us out okay so okay it gets my mind around some different video editing ideas video Generation video editing let's improve the quality of our video here with uh with a that sounds awesome love it excellent all right man it's a great conversation I guess I'll uh talk to you on the next one yeah man it was a great conversation and the thing is the demos were great great job with it are you putting your code up anywhere I should yeah I mean it's just a a single script so I totally can I just want to I just want to rip your DSP stuff off oh yeah please do super easy to work with with DSP I mean I think there's some fear with DSP because it's kind of hard to understand but once to get the general primitive also what I can do is I can send you I I did a basically code to prompt and a very terrible beautiful soup um script to scrape all of dsp's documentation and the pretty much their whole code base and I put it into a cloud project and so anytime I have DSP questions it actually generates full programs and it does it really well and so I almost all of that I bar I don't think I've actually written a line of DSP since I built that I just kind of copy and pasted out of anthropic so well what we got to do is use the research agent to learn about DSP take these links feed it through your fine tune thing to make our own model and we have a DSP bot right at our becking call yeah or even just make one giant uh prompt so we can prompt cast it with anthropic this all come in full circle now wait okay we got to see this a future episode yeah okay that sounds good that sounds good all right well we should we should save the rest of our conversation for a future episode this has been fun Mike let's uh let's do it again next week absolutely man have a great weekend thanks man you too see you [Music]",
    "video_url": "https://www.youtube.com/watch?v=uAo513GIwoU"
}